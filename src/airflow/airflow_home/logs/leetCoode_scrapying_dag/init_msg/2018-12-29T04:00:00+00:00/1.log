[2018-12-28 23:08:45,420] {models.py:1361} INFO - Dependencies all met for <TaskInstance: leetCoode_scrapying_dag.init_msg 2018-12-29T04:00:00+00:00 [queued]>
[2018-12-28 23:08:45,422] {models.py:1361} INFO - Dependencies all met for <TaskInstance: leetCoode_scrapying_dag.init_msg 2018-12-29T04:00:00+00:00 [queued]>
[2018-12-28 23:08:45,422] {models.py:1573} INFO - 
--------------------------------------------------------------------------------
Starting attempt 1 of 1
--------------------------------------------------------------------------------

[2018-12-28 23:08:45,429] {models.py:1595} INFO - Executing <Task(BashOperator): init_msg> on 2018-12-29T04:00:00+00:00
[2018-12-28 23:08:45,429] {base_task_runner.py:118} INFO - Running: ['bash', '-c', 'airflow run leetCoode_scrapying_dag init_msg 2018-12-29T04:00:00+00:00 --job_id 2 --raw -sd DAGS_FOLDER/scraping_scheduler_dag.py --cfg_path /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T/tmprwi695nz']
[2018-12-28 23:08:46,225] {base_task_runner.py:101} INFO - Job 2: Subtask init_msg [2018-12-28 23:08:46,225] {__init__.py:51} INFO - Using executor SequentialExecutor
[2018-12-28 23:08:46,382] {base_task_runner.py:101} INFO - Job 2: Subtask init_msg [2018-12-28 23:08:46,382] {models.py:271} INFO - Filling up the DagBag from /Users/zhonghengli/Documents/Insight/leetCodeProject/leetcode_score_monitoring/src/airflow/airflow_home/dags/scraping_scheduler_dag.py
[2018-12-28 23:08:46,447] {base_task_runner.py:101} INFO - Job 2: Subtask init_msg [2018-12-28 23:08:46,447] {cli.py:484} INFO - Running <TaskInstance: leetCoode_scrapying_dag.init_msg 2018-12-29T04:00:00+00:00 [running]> on host zhonghengsmbp2.fios-router.home
[2018-12-28 23:08:46,464] {bash_operator.py:74} INFO - Tmp dir root location: 
 /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T
[2018-12-28 23:08:46,464] {bash_operator.py:87} INFO - Temporary script location: /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T/airflowtmpe7k8nusz/init_msg64n3yyyy
[2018-12-28 23:08:46,465] {bash_operator.py:97} INFO - Running command: echo "Scrapy_Start!!"
[2018-12-28 23:08:46,474] {bash_operator.py:106} INFO - Output:
[2018-12-28 23:08:46,477] {bash_operator.py:110} INFO - Scrapy_Start!!
[2018-12-28 23:08:46,477] {bash_operator.py:114} INFO - Command exited with return code 0
[2018-12-28 23:08:50,427] {logging_mixin.py:95} INFO - [2018-12-28 23:08:50,426] {jobs.py:2627} INFO - Task exited with return code 0
