[2018-12-28 23:28:10,119] {models.py:1361} INFO - Dependencies all met for <TaskInstance: leetCoode_scrapying_dag.init_msg 2018-12-29T04:20:00+00:00 [queued]>
[2018-12-28 23:28:10,121] {models.py:1361} INFO - Dependencies all met for <TaskInstance: leetCoode_scrapying_dag.init_msg 2018-12-29T04:20:00+00:00 [queued]>
[2018-12-28 23:28:10,121] {models.py:1573} INFO - 
--------------------------------------------------------------------------------
Starting attempt 1 of 1
--------------------------------------------------------------------------------

[2018-12-28 23:28:10,129] {models.py:1595} INFO - Executing <Task(BashOperator): init_msg> on 2018-12-29T04:20:00+00:00
[2018-12-28 23:28:10,130] {base_task_runner.py:118} INFO - Running: ['bash', '-c', 'airflow run leetCoode_scrapying_dag init_msg 2018-12-29T04:20:00+00:00 --job_id 7 --raw -sd DAGS_FOLDER/scraping_scheduler_dag.py --cfg_path /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T/tmpd_mvrzgq']
[2018-12-28 23:28:10,982] {base_task_runner.py:101} INFO - Job 7: Subtask init_msg [2018-12-28 23:28:10,982] {__init__.py:51} INFO - Using executor SequentialExecutor
[2018-12-28 23:28:11,143] {base_task_runner.py:101} INFO - Job 7: Subtask init_msg [2018-12-28 23:28:11,143] {models.py:271} INFO - Filling up the DagBag from /Users/zhonghengli/Documents/Insight/leetCodeProject/leetcode_score_monitoring/src/airflow/airflow_home/dags/scraping_scheduler_dag.py
[2018-12-28 23:28:11,239] {base_task_runner.py:101} INFO - Job 7: Subtask init_msg [2018-12-28 23:28:11,238] {cli.py:484} INFO - Running <TaskInstance: leetCoode_scrapying_dag.init_msg 2018-12-29T04:20:00+00:00 [running]> on host zhonghengsmbp2.fios-router.home
[2018-12-28 23:28:11,262] {bash_operator.py:74} INFO - Tmp dir root location: 
 /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T
[2018-12-28 23:28:11,264] {bash_operator.py:87} INFO - Temporary script location: /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T/airflowtmpccumu_e1/init_msgzaxd9o2w
[2018-12-28 23:28:11,264] {bash_operator.py:97} INFO - Running command: echo "Scrapy_Start!!"
[2018-12-28 23:28:11,277] {bash_operator.py:106} INFO - Output:
[2018-12-28 23:28:11,281] {bash_operator.py:110} INFO - Scrapy_Start!!
[2018-12-28 23:28:11,281] {bash_operator.py:114} INFO - Command exited with return code 0
[2018-12-28 23:28:15,124] {logging_mixin.py:95} INFO - [2018-12-28 23:28:15,123] {jobs.py:2627} INFO - Task exited with return code 0
