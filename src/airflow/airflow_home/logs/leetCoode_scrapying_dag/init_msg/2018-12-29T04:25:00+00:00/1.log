[2018-12-28 23:30:01,394] {models.py:1361} INFO - Dependencies all met for <TaskInstance: leetCoode_scrapying_dag.init_msg 2018-12-29T04:25:00+00:00 [queued]>
[2018-12-28 23:30:01,397] {models.py:1361} INFO - Dependencies all met for <TaskInstance: leetCoode_scrapying_dag.init_msg 2018-12-29T04:25:00+00:00 [queued]>
[2018-12-28 23:30:01,397] {models.py:1573} INFO - 
--------------------------------------------------------------------------------
Starting attempt 1 of 1
--------------------------------------------------------------------------------

[2018-12-28 23:30:01,409] {models.py:1595} INFO - Executing <Task(BashOperator): init_msg> on 2018-12-29T04:25:00+00:00
[2018-12-28 23:30:01,409] {base_task_runner.py:118} INFO - Running: ['bash', '-c', 'airflow run leetCoode_scrapying_dag init_msg 2018-12-29T04:25:00+00:00 --job_id 13 --raw -sd DAGS_FOLDER/scraping_scheduler_dag.py --cfg_path /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T/tmpfhg5bav3']
[2018-12-28 23:30:02,243] {base_task_runner.py:101} INFO - Job 13: Subtask init_msg [2018-12-28 23:30:02,243] {__init__.py:51} INFO - Using executor SequentialExecutor
[2018-12-28 23:30:02,406] {base_task_runner.py:101} INFO - Job 13: Subtask init_msg [2018-12-28 23:30:02,406] {models.py:271} INFO - Filling up the DagBag from /Users/zhonghengli/Documents/Insight/leetCodeProject/leetcode_score_monitoring/src/airflow/airflow_home/dags/scraping_scheduler_dag.py
[2018-12-28 23:30:02,473] {base_task_runner.py:101} INFO - Job 13: Subtask init_msg [2018-12-28 23:30:02,473] {cli.py:484} INFO - Running <TaskInstance: leetCoode_scrapying_dag.init_msg 2018-12-29T04:25:00+00:00 [running]> on host zhonghengsmbp2.fios-router.home
[2018-12-28 23:30:02,488] {bash_operator.py:74} INFO - Tmp dir root location: 
 /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T
[2018-12-28 23:30:02,489] {bash_operator.py:87} INFO - Temporary script location: /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T/airflowtmpzxt9o0l5/init_msgl0ce4tph
[2018-12-28 23:30:02,489] {bash_operator.py:97} INFO - Running command: echo "Scrapy_Start!!"
[2018-12-28 23:30:02,499] {bash_operator.py:106} INFO - Output:
[2018-12-28 23:30:02,502] {bash_operator.py:110} INFO - Scrapy_Start!!
[2018-12-28 23:30:02,502] {bash_operator.py:114} INFO - Command exited with return code 0
[2018-12-28 23:30:06,381] {logging_mixin.py:95} INFO - [2018-12-28 23:30:06,380] {jobs.py:2627} INFO - Task exited with return code 0
