[2018-12-28 23:10:10,074] {models.py:1361} INFO - Dependencies all met for <TaskInstance: leetCoode_scrapying_dag.run_shell 2018-12-29T04:05:00+00:00 [queued]>
[2018-12-28 23:10:10,078] {models.py:1361} INFO - Dependencies all met for <TaskInstance: leetCoode_scrapying_dag.run_shell 2018-12-29T04:05:00+00:00 [queued]>
[2018-12-28 23:10:10,078] {models.py:1573} INFO - 
--------------------------------------------------------------------------------
Starting attempt 1 of 1
--------------------------------------------------------------------------------

[2018-12-28 23:10:10,085] {models.py:1595} INFO - Executing <Task(BashOperator): run_shell> on 2018-12-29T04:05:00+00:00
[2018-12-28 23:10:10,085] {base_task_runner.py:118} INFO - Running: ['bash', '-c', 'airflow run leetCoode_scrapying_dag run_shell 2018-12-29T04:05:00+00:00 --job_id 5 --raw -sd DAGS_FOLDER/scraping_scheduler_dag.py --cfg_path /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T/tmp0j64_x49']
[2018-12-28 23:10:10,774] {base_task_runner.py:101} INFO - Job 5: Subtask run_shell [2018-12-28 23:10:10,774] {__init__.py:51} INFO - Using executor SequentialExecutor
[2018-12-28 23:10:10,913] {base_task_runner.py:101} INFO - Job 5: Subtask run_shell [2018-12-28 23:10:10,913] {models.py:271} INFO - Filling up the DagBag from /Users/zhonghengli/Documents/Insight/leetCodeProject/leetcode_score_monitoring/src/airflow/airflow_home/dags/scraping_scheduler_dag.py
[2018-12-28 23:10:10,977] {base_task_runner.py:101} INFO - Job 5: Subtask run_shell [2018-12-28 23:10:10,976] {cli.py:484} INFO - Running <TaskInstance: leetCoode_scrapying_dag.run_shell 2018-12-29T04:05:00+00:00 [running]> on host zhonghengsmbp2.fios-router.home
[2018-12-28 23:10:10,992] {bash_operator.py:74} INFO - Tmp dir root location: 
 /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T
[2018-12-28 23:10:10,993] {bash_operator.py:87} INFO - Temporary script location: /var/folders/fz/pxkgsp6j3d946l3f71v3sj_00000gn/T/airflowtmpufudpgst/run_shellofid1h0y
[2018-12-28 23:10:10,993] {bash_operator.py:97} INFO - Running command: sh /Users/zhonghengli/Documents/Insight/leetCodeProject/leetcode_score_monitoring/src/Scraper/run.sh 
[2018-12-28 23:10:11,004] {bash_operator.py:106} INFO - Output:
[2018-12-28 23:10:11,018] {bash_operator.py:110} INFO - Scrapy_Start!!
[2018-12-28 23:10:12,685] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: leetCode_spider)
[2018-12-28 23:10:12,711] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 03:03:55) - [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Darwin-18.2.0-x86_64-i386-64bit
[2018-12-28 23:10:12,715] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'leetCode_spider', 'NEWSPIDER_MODULE': 'leetCode_spider.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['leetCode_spider.spiders']}
[2018-12-28 23:10:12,789] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.middleware] INFO: Enabled extensions:
[2018-12-28 23:10:12,789] {bash_operator.py:110} INFO - ['scrapy.extensions.corestats.CoreStats',
[2018-12-28 23:10:12,789] {bash_operator.py:110} INFO -  'scrapy.extensions.telnet.TelnetConsole',
[2018-12-28 23:10:12,789] {bash_operator.py:110} INFO -  'scrapy.extensions.memusage.MemoryUsage',
[2018-12-28 23:10:12,789] {bash_operator.py:110} INFO -  'scrapy.extensions.logstats.LogStats']
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO - ['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.retry.RetryMiddleware',
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
[2018-12-28 23:10:12,854] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
[2018-12-28 23:10:12,855] {bash_operator.py:110} INFO -  'scrapy.downloadermiddlewares.stats.DownloaderStats']
[2018-12-28 23:10:12,858] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.middleware] INFO: Enabled spider middlewares:
[2018-12-28 23:10:12,858] {bash_operator.py:110} INFO - ['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
[2018-12-28 23:10:12,858] {bash_operator.py:110} INFO -  'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
[2018-12-28 23:10:12,858] {bash_operator.py:110} INFO -  'scrapy.spidermiddlewares.referer.RefererMiddleware',
[2018-12-28 23:10:12,859] {bash_operator.py:110} INFO -  'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
[2018-12-28 23:10:12,859] {bash_operator.py:110} INFO -  'scrapy.spidermiddlewares.depth.DepthMiddleware']
[2018-12-28 23:10:12,859] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.middleware] INFO: Enabled item pipelines:
[2018-12-28 23:10:12,859] {bash_operator.py:110} INFO - []
[2018-12-28 23:10:12,859] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.core.engine] INFO: Spider opened
[2018-12-28 23:10:12,866] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
[2018-12-28 23:10:12,867] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
[2018-12-28 23:10:12,945] {bash_operator.py:110} INFO - 2018-12-28 23:10:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://leetcode.com/robots.txt> (referer: None)
[2018-12-28 23:10:13,057] {bash_operator.py:110} INFO - 2018-12-28 23:10:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://leetcode.com/zl1761/> from <GET https://leetcode.com/zl1761>
[2018-12-28 23:10:13,118] {bash_operator.py:110} INFO - 2018-12-28 23:10:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://leetcode.com/hideaki/> from <GET https://leetcode.com/hideaki>
[2018-12-28 23:10:13,156] {bash_operator.py:110} INFO - 2018-12-28 23:10:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://leetcode.com/oreki47/> from <GET https://leetcode.com/oreki47>
[2018-12-28 23:10:13,251] {bash_operator.py:110} INFO - 2018-12-28 23:10:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://leetcode.com/zl1761/> (referer: None)
[2018-12-28 23:10:13,374] {bash_operator.py:110} INFO - 2018-12-28 23:10:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://leetcode.com/oreki47/> (referer: None)
[2018-12-28 23:10:13,666] {bash_operator.py:110} INFO - 2018-12-28 23:10:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://leetcode.com/hideaki/> (referer: None)
[2018-12-28 23:10:13,785] {bash_operator.py:110} INFO - 2018-12-28 23:10:13 [scrapy.core.engine] INFO: Closing spider (finished)
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO - 2018-12-28 23:10:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO - {'downloader/request_bytes': 1902,
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'downloader/request_count': 7,
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'downloader/request_method_count/GET': 7,
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'downloader/response_bytes': 40026,
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'downloader/response_count': 7,
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'downloader/response_status_count/200': 4,
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'downloader/response_status_count/301': 3,
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'finish_reason': 'finished',
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'finish_time': datetime.datetime(2018, 12, 29, 4, 10, 13, 785618),
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'log_count/DEBUG': 8,
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'log_count/INFO': 7,
[2018-12-28 23:10:13,786] {bash_operator.py:110} INFO -  'memusage/max': 92372992,
[2018-12-28 23:10:13,787] {bash_operator.py:110} INFO -  'memusage/startup': 92372992,
[2018-12-28 23:10:13,787] {bash_operator.py:110} INFO -  'response_received_count': 4,
[2018-12-28 23:10:13,787] {bash_operator.py:110} INFO -  'scheduler/dequeued': 6,
[2018-12-28 23:10:13,787] {bash_operator.py:110} INFO -  'scheduler/dequeued/memory': 6,
[2018-12-28 23:10:13,787] {bash_operator.py:110} INFO -  'scheduler/enqueued': 6,
[2018-12-28 23:10:13,787] {bash_operator.py:110} INFO -  'scheduler/enqueued/memory': 6,
[2018-12-28 23:10:13,787] {bash_operator.py:110} INFO -  'start_time': datetime.datetime(2018, 12, 29, 4, 10, 12, 866160)}
[2018-12-28 23:10:13,787] {bash_operator.py:110} INFO - 2018-12-28 23:10:13 [scrapy.core.engine] INFO: Spider closed (finished)
[2018-12-28 23:10:13,817] {bash_operator.py:110} INFO - user_model: {'user_id': 'zl1761', 'num_solved': 124, 'num_accepts': 360, 'num_submissions': 630, 'accepted_percentage': 57.1, 'finished_contests': 0, 'date': '2018-12-28'}
[2018-12-28 23:10:13,817] {bash_operator.py:110} INFO - user_model: {'user_id': 'hideaki', 'num_solved': 244, 'num_accepts': 400, 'num_submissions': 855, 'accepted_percentage': 46.8, 'finished_contests': 3, 'date': '2018-12-28'}
[2018-12-28 23:10:13,817] {bash_operator.py:110} INFO - user_model: {'user_id': 'oreki47', 'num_solved': 30, 'num_accepts': 57, 'num_submissions': 139, 'accepted_percentage': 41.0, 'finished_contests': 0, 'date': '2018-12-28'}
[2018-12-28 23:10:13,817] {bash_operator.py:110} INFO - export fellows.csv
[2018-12-28 23:10:13,972] {bash_operator.py:114} INFO - Command exited with return code 0
[2018-12-28 23:10:15,079] {logging_mixin.py:95} INFO - [2018-12-28 23:10:15,079] {jobs.py:2627} INFO - Task exited with return code 0
